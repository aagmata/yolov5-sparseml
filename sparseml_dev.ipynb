{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+XMYJeSpyBryjXpoj3YDX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aagmata/yolov5-sparseml/blob/main/sparseml_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing libraries"
      ],
      "metadata": {
        "id": "1jwkvhNa0JYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sparseml[torchvision]\n",
        "!pip3 install numpy --upgrade"
      ],
      "metadata": {
        "id": "rDHg_Cb80MY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning through sparseml"
      ],
      "metadata": {
        "id": "qlu2wkVZ2e6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sparseml.yolov5.train \\\n",
        "  --weights zoo:cv/detection/yolov5-m6/pytorch/ultralytics/voc/pruned75-none?recipe_type=transfer_learn \\\n",
        "  --recipe ./recipes/recipe_1.yaml \\\n",
        "  --data coco128.yaml \\\n",
        "  --patience 0 \\\n",
        "  --hyp hyps/hyp.finetune.yaml \\\n",
        "  --imgsz 1280"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tCehQZm50ly",
        "outputId": "1003bf2d-6a4c-4834-a416-5955fcddf2b0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=zoo:cv/detection/yolov5-n/pytorch/ultralytics/coco/pruned40-none?recipe_type=transfer_learn, cfg=, teacher_weights=, data=coco128.yaml, data_path=, hyp=hyps/hyp.finetune.yaml, epochs=300, batch_size=16, gradient_accum_steps=-1, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/yolov5_runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=0, freeze=[0], save_period=-1, seed=0, local_rank=-1, recipe=./recipes/recipe_1.yaml, recipe_args=None, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "YOLOv5 🚀 2023-4-18 Python-3.9.16 torch-1.12.0+cu102 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0032, lrf=0.12, momentum=0.843, weight_decay=0.00036, warmup_epochs=2.0, warmup_momentum=0.5, warmup_bias_lr=0.05, box=0.0296, cls=0.243, cls_pw=0.631, obj=0.301, obj_pw=0.911, iou_t=0.2, anchor_t=2.91, fl_gamma=0.0, hsv_h=0.0138, hsv_s=0.664, hsv_v=0.464, degrees=0.373, translate=0.245, scale=0.898, shear=0.602, perspective=0.0, flipud=0.00856, fliplr=0.5, mosaic=1.0, mixup=0.243, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/yolov5_runs/train', view at http://localhost:6006/\n",
            "2023-04-18 01:34:11.004417: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-18 01:34:12.021671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  yolov5.models.common.Conv               [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  yolov5.models.common.Conv               [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  yolov5.models.common.C3                 [32, 32, 1]                   \n",
            "  3                -1  1     18560  yolov5.models.common.Conv               [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  yolov5.models.common.C3                 [64, 64, 2]                   \n",
            "  5                -1  1     73984  yolov5.models.common.Conv               [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  yolov5.models.common.C3                 [128, 128, 3]                 \n",
            "  7                -1  1    295424  yolov5.models.common.Conv               [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1]                 \n",
            "  9                -1  1    164608  yolov5.models.common.SPPF               [256, 256, 5]                 \n",
            " 10                -1  1     33024  yolov5.models.common.Conv               [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 13                -1  1     90880  yolov5.models.common.C3                 [256, 128, 1, False]          \n",
            " 14                -1  1      8320  yolov5.models.common.Conv               [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 17                -1  1     22912  yolov5.models.common.C3                 [128, 64, 1, False]           \n",
            " 18                -1  1     36992  yolov5.models.common.Conv               [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 20                -1  1     74496  yolov5.models.common.C3                 [128, 128, 1, False]          \n",
            " 21                -1  1    147712  yolov5.models.common.Conv               [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  yolov5.models.common.Concat             [1]                           \n",
            " 23                -1  1    296448  yolov5.models.common.C3                 [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1    115005  yolov5.models.yolo.Detect               [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "Model summary: 214 layers, 1872157 parameters, 1872157 gradients, 4.6 GFLOPs\n",
            "\n",
            "Transferred 349/349 items from /root/.cache/sparsezoo/78625a7f-9bee-4472-a165-e9f2de04344b/training/model.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.0032) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00036), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/datasets/coco128/labels/train2017.cache' images and labels... 126 found, 2 missing, 0 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m2.86 anchors/target, 0.942 Best Possible Recall (BPR). Anchors are a poor fit to dataset ⚠️, attempting to improve...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mWARNING ⚠️ Extremely small objects found: 1 of 929 labels are <3 pixels in size\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mRunning kmeans for 9 anchors on 929 points...\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6503: 100% 1000/1000 [00:02<00:00, 369.49it/s]\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mthr=0.34: 0.9462 best possible recall, 2.72 anchors past thr\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mn=9, img_size=1280, metric_all=0.266/0.664-mean/best, past_thr=0.545-mean: 29,44, 95,54, 71,165, 175,134, 227,279, 294,558, 542,400, 739,747, 1219,850\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0mDone ✅ (optional: update model *.yaml to use these anchors in the future)\n",
            "Plotting labels to /content/yolov5_runs/train/exp9/labels.jpg... \n",
            "2023-04-18 01:34:30 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/18-04-2023_01.34.30.log\n",
            "Logging all SparseML modifier-level logs to sparse_logs/18-04-2023_01.34.30.log\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mSparse training detected. Wrapping training process with SparseML\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mDisabling LR scheduler, managing LR using SparseML recipe\n",
            "\u001b[34m\u001b[1mNeural Magic: \u001b[0mOverriding total number of training epochs with value from recipe: 10\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolov5_runs/train/exp9\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Adjusted gradient clipping threshold to 10.0\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9       8.5G    0.06817    0.03452    0.02114        315       1280:  75% 6/8 [00:15<00:05,  2.56s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/sparseml.yolov5.train\", line 8, in <module>\n",
            "    sys.exit(train())\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/yolov5/scripts.py\", line 41, in train\n",
            "    train_run(**vars(opt))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/yolov5/train.py\", line 730, in run\n",
            "    main(opt)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/yolov5/train.py\", line 630, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/yolov5/train.py\", line 390, in train\n",
            "    scaler.step(optimizer)  # optimizer.step\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/optim/manager.py\", line 172, in step\n",
            "    return self._perform_wrapped_step(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/optim/manager.py\", line 209, in _perform_wrapped_step\n",
            "    self._wrapped_manager.update(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/optim/manager.py\", line 589, in update\n",
            "    mod.scheduled_update(module, optimizer, epoch, steps_per_epoch)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/sparsification/modifier.py\", line 620, in scheduled_update\n",
            "    self.update(module, optimizer, epoch=epoch, steps_per_epoch=steps_per_epoch)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/sparsification/modifier.py\", line 452, in wrapper\n",
            "    out = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/sparsification/pruning/modifier_pruning_base.py\", line 354, in update\n",
            "    self.check_mask_update(module, epoch, steps_per_epoch)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/sparsification/pruning/modifier_pruning_base.py\", line 388, in check_mask_update\n",
            "    self._module_masks.update_param_masks(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/sparsification/pruning/mask_params.py\", line 380, in update_param_masks\n",
            "    return self.set_param_masks(masks)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/sparsification/pruning/mask_params.py\", line 324, in set_param_masks\n",
            "    mask_diff = mask_difference(self._param_masks[idx], value)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sparseml/pytorch/utils/helpers.py\", line 694, in mask_difference\n",
            "    return -1.0 * newly_masked + newly_unmasked\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating fine-tuned model"
      ],
      "metadata": {
        "id": "sTXwEE1FA7o1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparseml.yolov5.validation \\\n",
        "  --weights \"zoo:cv/detection/yolov5-m6/pytorch/ultralytics/voc/pruned75-none\" \\\n",
        "  --data VOC.yaml \\\n",
        "  --imgsz 1280"
      ],
      "metadata": {
        "id": "e3RhT9jVASDc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}